{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37432cbe-47e3-46bb-8074-6f4f5822acde",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reader, Dataset, SVD\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score, mean_average_precision\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_average_precision\n",
    "\n",
    "# Load the data\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(your_data, reader)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# Use the SVD algorithm to make predictions\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Compute and print evaluation metrics\n",
    "precision = precision_score(testset, predictions)\n",
    "recall = recall_score(testset, predictions)\n",
    "f1 = f1_score(testset, predictions)\n",
    "map = mean_average_precision(testset, predictions)\n",
    "\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1-score: ', f1)\n",
    "print('Mean Average Precision: ', map)\n",
    "\n",
    "# Create a comprehensive report detailing the design and architecture of the shopping recommender system\n",
    "# ...\n",
    "\n",
    "# Create a user guide or README file describing how to install and run the end-to-end pipeline\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f91a89b-1f06-4a11-8ea6-8e0c4aa7986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Using cached scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\aanchal\\software setup\\python\\lib\\site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\aanchal\\software setup\\python\\lib\\site-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\aanchal\\software setup\\python\\lib\\site-packages (from scikit-surprise) (1.13.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml): started\n",
      "  Building wheel for scikit-surprise (pyproject.toml): finished with status 'error'\n",
      "Failed to build scikit-surprise\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for scikit-surprise (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [117 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\accuracy.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\dataset.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\dump.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\reader.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\trainset.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\utils.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\__init__.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\__main__.py -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  creating build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "  copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-cpython-312\\surprise\\model_selection\n",
      "  creating build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  running egg_info\n",
      "  writing scikit_surprise.egg-info\\PKG-INFO\n",
      "  writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "  writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "  writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "  writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "  dependency C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "  reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*.so' found under directory 'surprise'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\DELL\\AppData\\Local\\Temp\\pip-build-env-f21r2xd8\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'surprise.prediction_algorithms' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'surprise.prediction_algorithms' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'surprise.prediction_algorithms' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'surprise.prediction_algorithms' to be distributed and are\n",
      "          already explicitly excluding 'surprise.prediction_algorithms' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  copying surprise\\similarities.c -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\similarities.pyx -> build\\lib.win-amd64-cpython-312\\surprise\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-cpython-312\\surprise\\prediction_algorithms\n",
      "  running build_ext\n",
      "  building 'surprise.similarities' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-surprise\n",
      "ERROR: Could not build wheels for scikit-surprise, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84f96d8b-4a09-4099-9cd1-4c6de95f1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(data):\n",
    "    # Handle missing values, remove duplicates, etc.\n",
    "    pass\n",
    "\n",
    "def transform_data(data):\n",
    "    # Transform data into user-item matrix\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3fe487-7f69-4eff-ad6c-0b677ab5223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def user_based_collaborative_filtering(user_item_matrix):\n",
    "    # Calculate user similarities\n",
    "    user_similarities = cosine_similarity(user_item_matrix)\n",
    "    # Generate recommendations\n",
    "    pass\n",
    "\n",
    "def item_based_collaborative_filtering(user_item_matrix):\n",
    "    # Calculate item similarities\n",
    "    item_similarities = cosine_similarity(user_item_matrix.T)\n",
    "    # Generate recommendations\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993c1da9-829c-4dd8-a3d9-9637f4653215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def content_based_filtering(item_features):\n",
    "    # Calculate item similarities\n",
    "    item_similarities = cosine_similarity(item_features)\n",
    "    # Generate recommendations\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f6d4d82-dd81-4bb8-99e7-538dc39978ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'collaborative_filtering'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollaborative_filtering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m user_based_collaborative_filtering\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontent_based_filtering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m content_based_filtering\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhybrid_model\u001b[39m(user_item_matrix, item_features):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Combine collaborative and content-based filtering\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'collaborative_filtering'"
     ]
    }
   ],
   "source": [
    "from collaborative_filtering import user_based_collaborative_filtering\n",
    "from content_based_filtering import content_based_filtering\n",
    "\n",
    "def hybrid_model(user_item_matrix, item_features):\n",
    "    # Combine collaborative and content-based filtering\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "859b5e30-6d25-4eea-949a-9a941835beaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_preprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_data, transform_data\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollaborative_filtering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m user_based_collaborative_filtering\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontent_based_filtering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m content_based_filtering\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_preprocessing'"
     ]
    }
   ],
   "source": [
    "\n",
    "from data_preprocessing import clean_data, transform_data\n",
    "from collaborative_filtering import user_based_collaborative_filtering\n",
    "from content_based_filtering import content_based_filtering\n",
    "from hybrid_model import hybrid_model\n",
    "from evaluation import evaluate_recommendations\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"data.csv\")\n",
    "    # Clean and preprocess data\n",
    "    clean_data(data)\n",
    "    user_item_matrix = transform_data(data)\n",
    "    # Generate recommendations\n",
    "    recommendations = hybrid_model(user_item_matrix, item_features)\n",
    "    # Evaluate recommendations\n",
    "    evaluate_recommendations(recommendations, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41e8d415-d352-4f87-b52d-e0ff905d7418",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mean_average_precision' from 'sklearn.metrics' (E:\\aanchal\\software setup\\python\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_recall_fscore_support, mean_average_precision\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_recommendations\u001b[39m(recommendations, actual):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Calculate precision, recall, F1-score, and mean average precision\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'mean_average_precision' from 'sklearn.metrics' (E:\\aanchal\\software setup\\python\\Lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, mean_average_precision\n",
    "\n",
    "def evaluate_recommendations(recommendations, actual):\n",
    "    # Calculate precision, recall, F1-score, and mean average precision\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca50c1a3-05f1-434f-ab67-d0bcd6602709",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_preprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_data, transform_data\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollaborative_filtering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m user_based_collaborative_filtering\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontent_based_filtering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m content_based_filtering\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_preprocessing'"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import clean_data, transform_data\n",
    "from collaborative_filtering import user_based_collaborative_filtering\n",
    "from content_based_filtering import content_based_filtering\n",
    "from hybrid_model import hybrid_model\n",
    "from evaluation import evaluate_recommendations\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"data.csv\")\n",
    "    # Clean and preprocess data\n",
    "    clean_data(data)\n",
    "    user_item_matrix = transform_data(data)\n",
    "    # Generate recommendations\n",
    "    recommendations = hybrid_model(user_item_matrix, item_features)\n",
    "    # Evaluate recommendations\n",
    "    evaluate_recommendations(recommendations, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf5d13-c70f-4507-b21b-d6c61f15fcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
